import streamlit as st
from openai import OpenAI
import os
import tempfile
import shutil
import zipfile
from concurrent.futures import ThreadPoolExecutor, as_completed

# âœ… OpenAI SDK v1+
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ğŸ“ Markdown ìë™ ë³‘í•© ë¶„ë¥˜ê¸°", page_icon="ğŸ“š", layout="wide")

# âœ… ì œëª© ë° ì„¤ëª…
st.title("ğŸ“ ChatGPT ê¸°ë°˜ Markdown ìë™ ë¶„ë¥˜ + ë³‘í•© ë„êµ¬")
st.markdown("""
ì—…ë¡œë“œí•œ Markdown íŒŒì¼ë“¤ì„ GPTê°€ ìë™ ë¶„ì„í•˜ì—¬ **ì‹œë„ˆì§€ ìˆëŠ” ì£¼ì œ ê·¸ë£¹**ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.  
ìµœëŒ€ 1000ê°œì˜ íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìœ¼ë©°, ê²°ê³¼ëŠ” ZIPìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

# âœ… ë ˆì´ì•„ì›ƒ ë¶„í•  (ì™¼ìª½: ì—…ë¡œë“œ / ì˜¤ë¥¸ìª½: ì•ˆë‚´ ë° ZIP ë‹¤ìš´ë¡œë“œ)
left_col, right_col = st.columns([1, 1.2])

# âœ… íŒŒì¼ ì—…ë¡œë“œ
with left_col:
    uploaded_files = st.file_uploader(
        "â¬†ï¸ Markdown (.md) íŒŒì¼ ì—…ë¡œë“œ (ìµœëŒ€ 1000ê°œ)",
        type="md",
        accept_multiple_files=True
    )

# âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ë³€ìˆ˜
grouped = {}
saved_files = []
zip_path = ""
file_infos = []

# âœ… GPT ìš”ì•½ í•¨ìˆ˜
def get_topic_and_summary(filename, content):
    prompt = f"""
ë‹¤ìŒì€ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œì…ë‹ˆë‹¤. ì•„ë˜ ë¬¸ì„œì˜ ì£¼ìš” ì£¼ì œë¥¼ ì§§ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ, í•µì‹¬ ìš”ì•½ë„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ì¶œë ¥ í˜•ì‹:
ì£¼ì œ: [ì£¼ì œëª…]
ìš”ì•½: [ìš”ì•½ë‚´ìš©]

ë¬¸ì„œ ì œëª©: {filename}
ë‚´ìš©:
{content[:1000].rsplit('\\n', 1)[0]}...
"""
    try:
        res = client.chat.completions.create(
            model="gpt-5-nano",  # gpt-5-nano ì‚¬ìš©
            messages=[{"role": "user", "content": prompt}]
        )
        text = res.choices[0].message.content.strip()
        topic, summary = "Unknown", ""
        for line in text.split("\n"):
            if line.lower().startswith("ì£¼ì œ:"):
                topic = line.split(":", 1)[1].strip()
            elif line.lower().startswith("ìš”ì•½:"):
                summary = line.split(":", 1)[1].strip()
        return topic, summary
    except Exception as e:
        return "Unknown", f"â— ì˜¤ë¥˜: {str(e)}"

# âœ… GPT ê·¸ë£¹í™” í•¨ìˆ˜
def get_grouped_topics(file_infos):
    merge_prompt = """
ë‹¤ìŒì€ ì—¬ëŸ¬ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ì£¼ì œ ë° ìš”ì•½ì…ë‹ˆë‹¤. ì£¼ì œì™€ ìš”ì•½ì´ ìœ ì‚¬í•˜ê±°ë‚˜ ê´€ë ¨ ìˆëŠ” íŒŒì¼ë¼ë¦¬ ë¬¶ì–´ 5~10ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ ì£¼ì„¸ìš”.
ê·¸ë¦¬ê³  ê° ê·¸ë£¹ì— ì ì ˆí•œ ëŒ€í‘œ í‚¤ì›Œë“œë¥¼ 3~5ê°œ ìƒì„±í•´ì£¼ì„¸ìš”.
ì¶œë ¥ í˜•ì‹:
[ê·¸ë£¹ëª…]: íŒŒì¼1.md, íŒŒì¼2.md
í‚¤ì›Œë“œ: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3

ëª©ë¡:
"""
    for info in file_infos:
        merge_prompt += f"- {info['filename']}: {info['topic']} / {info['summary']}\n"

    try:
        res = client.chat.completions.create(
            model="gpt-5-nano",
            messages=[{"role": "user", "content": merge_prompt}]
        )
        text = res.choices[0].message.content.strip()
        groups, current_group = {}, None
        for line in text.split("\n"):
            if ":" in line and ".md" in line:
                topic, files_str = line.split(":", 1)
                filenames = [f.strip() for f in files_str.split(",") if f.strip()]
                current_group = topic.strip()
                groups[current_group] = {"files": filenames, "keywords": []}
            elif "í‚¤ì›Œë“œ:" in line and current_group:
                keyword_str = line.split(":", 1)[1]
                groups[current_group]["keywords"] = [k.strip() for k in keyword_str.split(",")]
        return groups
    except Exception as e:
        st.error(f"ë³‘í•© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

# âœ… ë©”ì¸ ì²˜ë¦¬ ë¡œì§
if uploaded_files:
    st.subheader("ğŸ“Š íŒŒì¼ ë¶„ì„ ë° ë³‘í•© ì¤‘...")

    future_to_file = {}
    seen_files = set()

    # â–¶ï¸ í•˜ë‹¨ ë ˆì´ì•„ì›ƒ: ì§„í–‰ ë°” ë° ë¡œê·¸ êµ¬ì—­
    progress = st.progress(0.0)
    status_text = st.empty()
    log_container = st.container()

    with ThreadPoolExecutor(max_workers=5) as executor:
        for uploaded_file in uploaded_files:
            filename = uploaded_file.name
            if filename in seen_files:
                continue
            seen_files.add(filename)
            content = uploaded_file.read().decode("utf-8")
            future = executor.submit(get_topic_and_summary, filename, content)
            future_to_file[future] = {"filename": filename, "content": content}

        for i, future in enumerate(as_completed(future_to_file)):
            topic, summary = future.result()
            info = future_to_file[future]
            info["topic"] = topic
            info["summary"] = summary
            file_infos.append(info)

            # âœ… ì§„í–‰ë¥  ë° ë¡œê·¸ ì¶œë ¥
            percent = (i + 1) / len(future_to_file)
            progress.progress(percent)
            status_text.markdown(f"ğŸ“„ ë¶„ì„ ì¤‘: {i+1}/{len(future_to_file)}ê°œ ì™„ë£Œ")
            log_container.markdown(f"âœ… **{info['filename']}** â†’ ì£¼ì œ: _{topic}_ / ìš”ì•½: _{summary}_")

    # âœ… ê·¸ë£¹ ìƒì„±
    grouped = get_grouped_topics(file_infos)

    # âœ… ì„ì‹œ ë””ë ‰í† ë¦¬ ë° ZIP ìƒì„±
    temp_dir = tempfile.mkdtemp()
    for topic, group_data in grouped.items():
        filenames = group_data["files"]
        keywords = group_data.get("keywords", [])
        folder = os.path.join(temp_dir, topic.replace(" ", "_"))
        os.makedirs(folder, exist_ok=True)

        # âœ… README ìƒì„±
        readme_path = os.path.join(folder, "README.md")
        with open(readme_path, "w", encoding="utf-8") as readme:
            readme.write(f"# {topic}\n\n")
            if keywords:
                readme.write(f"**ğŸ“Œ í‚¤ì›Œë“œ:** {', '.join(keywords)}\n\n")
            readme.write("## ğŸ“„ í¬í•¨ëœ íŒŒì¼ ëª©ë¡\n")
            for f in filenames:
                readme.write(f"- {f}\n")
            saved_files.append(readme_path)

        # âœ… ì‹¤ì œ íŒŒì¼ ë³µì‚¬
        for f in filenames:
            match = next((item for item in file_infos if item["filename"] == f), None)
            if match:
                full_path = os.path.join(folder, f)
                with open(full_path, "w", encoding="utf-8") as md_file:
                    md_file.write(match["content"])
                saved_files.append(full_path)

    # âœ… ZIP ì••ì¶•
    zip_path = os.path.join(temp_dir, "merged_markdowns.zip")
    with zipfile.ZipFile(zip_path, "w") as zipf:
        for filepath in saved_files:
            arcname = os.path.relpath(filepath, temp_dir)
            zipf.write(filepath, arcname)

# âœ… ì˜¤ë¥¸ìª½ ë‹¤ìš´ë¡œë“œ ì˜ì—­
with right_col:
    if grouped and saved_files:
        with open(zip_path, "rb") as fp:
            st.download_button("ğŸ“¦ ë³‘í•© ZIP ë‹¤ìš´ë¡œë“œ", fp, file_name="merged_markdowns.zip", mime="application/zip")
        st.success("âœ… íŒŒì¼ ë¶„ì„ ì™„ë£Œ. ZIP íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
    else:
        st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì´ ì‹œì‘ë˜ê³ , ì—¬ê¸°ì—ì„œ ê²°ê³¼ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
