# ğŸ“ Streamlit App: Markdown Auto Classifier (chunked, OpenAI v1+)
import streamlit as st
from openai import OpenAI
import os
import tempfile
import shutil
import zipfile
from concurrent.futures import ThreadPoolExecutor, as_completed
from uuid import uuid4
from math import ceil

# âœ… Initialize OpenAI client (SDK v1+)
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… Page Setup
st.set_page_config(page_title="ğŸ“ Markdown ìë™ ë³‘í•© ë¶„ë¥˜ê¸°", page_icon="ğŸ“š", layout="wide")
st.title("ğŸ“ ChatGPT ê¸°ë°˜ Markdown ìë™ ë¶„ë¥˜ + ì£¼ì œ ë³‘í•©")
st.markdown("""
ì—…ë¡œë“œí•œ Markdown íŒŒì¼ë“¤ì„ GPTê°€ ìë™ ë¶„ì„í•˜ì—¬ **ì‹œë„ˆì§€ ìˆëŠ” ì£¼ì œ ê·¸ë£¹**ìœ¼ë¡œ ë¬¶ì–´ì¤ë‹ˆë‹¤.  
ë§ì€ íŒŒì¼(ì˜ˆ: 80ê°œ ì´ìƒ)ì€ ìë™ìœ¼ë¡œ ì—¬ëŸ¬ ë²ˆì— ë‚˜ëˆ ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
""")

# âœ… Upload Area
uploaded_files = st.file_uploader("â¬†ï¸ Markdown (.md) íŒŒì¼ ì—…ë¡œë“œ", type="md", accept_multiple_files=True)

# âœ… Refresh Button
st.markdown("""
<style>
.button-container {
    display: flex;
    gap: 10px;
    margin-bottom: 20px;
}
.button-container .refresh-button button {
    background-color: #4CAF50;
    color: white;
    font-weight: bold;
    width: 100%;
}
</style>
<div class="button-container">
  <div class="refresh-button">
    <form action="?refresh=1">
      <button type="submit">ğŸ”„ ì „ì²´ ìƒˆë¡œê³ ì¹¨</button>
    </form>
  </div>
</div>
""", unsafe_allow_html=True)

if "refresh" in st.experimental_get_query_params():
    st.experimental_rerun()

# âœ… GPT: Topic + Summary
def get_topic_and_summary(filename, content):
    prompt = f"""
ë‹¤ìŒì€ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œì…ë‹ˆë‹¤. ì•„ë˜ ë¬¸ì„œì˜ ì£¼ìš” ì£¼ì œë¥¼ ì§§ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ, í•µì‹¬ ìš”ì•½ë„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ì¶œë ¥ í˜•ì‹:
ì£¼ì œ: [ì£¼ì œëª…]
ìš”ì•½: [ìš”ì•½ë‚´ìš©]

ë¬¸ì„œ ì œëª©: {filename}
ë‚´ìš©:
{content[:1000].rsplit('\\n', 1)[0]}...
"""
    try:
        res = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        text = res.choices[0].message.content.strip()
        topic, summary = "Unknown", ""
        for line in text.split("\n"):
            if line.lower().startswith("ì£¼ì œ:"):
                topic = line.split(":", 1)[1].strip()
            elif line.lower().startswith("ìš”ì•½:"):
                summary = line.split(":", 1)[1].strip()
        return topic, summary
    except Exception as e:
        return "Unknown", ""

# âœ… GPT: Grouping by chunk (â‰¤30 files per batch)
def get_grouped_topics_chunked(file_infos, chunk_size=30):
    total_chunks = ceil(len(file_infos) / chunk_size)
    grouped = {}

    for i in range(total_chunks):
        chunk = file_infos[i * chunk_size:(i + 1) * chunk_size]
        prompt = """
ë‹¤ìŒì€ ì—¬ëŸ¬ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ì£¼ì œ ë° ìš”ì•½ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ **ëª¨ë“  íŒŒì¼ì„ í¬í•¨í•˜ì—¬**, ê´€ë ¨ëœ íŒŒì¼ë¼ë¦¬ ë¬¶ì–´ 3~10ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ ì£¼ì„¸ìš”.
ê° ê·¸ë£¹ì— 3~5ê°œì˜ í‚¤ì›Œë“œë„ ìƒì„±í•´ì£¼ì„¸ìš”.
ì¶œë ¥ í˜•ì‹:
[ê·¸ë£¹ëª…]: íŒŒì¼1.md, íŒŒì¼2.md
í‚¤ì›Œë“œ: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3

ëª©ë¡:
"""
        for info in chunk:
            prompt += f"- {info['unique_filename']}: {info['topic']} / {info['summary']}\n"

        try:
            res = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}]
            )
            text = res.choices[0].message.content.strip()
            current_group = None
            for line in text.split("\n"):
                if ":" in line and ".md" in line:
                    topic, files_str = line.split(":", 1)
                    filenames = [f.strip() for f in files_str.split(",") if f.strip()]
                    current_group = topic.strip() + f" (Batch {i+1})"
                    grouped[current_group] = {"files": filenames, "keywords": []}
                elif "í‚¤ì›Œë“œ:" in line and current_group:
                    keyword_str = line.split(":", 1)[1]
                    grouped[current_group]["keywords"] = [k.strip() for k in keyword_str.split(",")]
        except Exception as e:
            st.warning(f"âš ï¸ ê·¸ë£¹ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    return grouped

# âœ… Main Logic
if uploaded_files:
    st.subheader("ğŸ“Š íŒŒì¼ ë¶„ì„ ë° ë³‘í•© ì¤‘...")
    file_infos = []
    file_id_map = {}
    future_to_file = {}

    with ThreadPoolExecutor(max_workers=5) as executor:
        progress = st.progress(0.0)
        status_text = st.empty()

        for uploaded_file in uploaded_files:
            original_name = uploaded_file.name
            unique_filename = f"{uuid4().hex[:8]}_{original_name}"
            content = uploaded_file.read().decode("utf-8")
            future = executor.submit(get_topic_and_summary, original_name, content)
            future_to_file[future] = {
                "filename": original_name,
                "unique_filename": unique_filename,
                "content": content,
            }

        for i, future in enumerate(as_completed(future_to_file)):
            result = future.result()
            info = future_to_file[future]
            info["topic"], info["summary"] = result
            file_infos.append(info)
            file_id_map[info["unique_filename"]] = info
            percent = (i + 1) / len(future_to_file)
            progress.progress(percent)
            status_text.markdown(f"ğŸ“„ ë¶„ì„ ì¤‘: {i+1}/{len(future_to_file)}ê°œ ì™„ë£Œ ({int(percent * 100)}%)")

    grouped = get_grouped_topics_chunked(file_infos)

    st.subheader("ğŸ§¾ ë¶„ë¥˜ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
    temp_dir = tempfile.mkdtemp()
    saved_files = []

    for group_name, data in grouped.items():
        filenames = data["files"]
        keywords = data.get("keywords", [])
        st.markdown(f"### ğŸ“ {group_name}")
        st.markdown(f"- ğŸ”‘ í‚¤ì›Œë“œ: {', '.join(keywords)}")
        st.markdown(f"- ğŸ“„ íŒŒì¼ ìˆ˜: {len(filenames)}")

        folder = os.path.join(temp_dir, group_name.replace(" ", "_").replace("/", "_"))
        os.makedirs(folder, exist_ok=True)

        readme_path = os.path.join(folder, "README.md")
        with open(readme_path, "w", encoding="utf-8") as readme:
            readme.write(f"# {group_name}\n\n")
            if keywords:
                readme.write(f"**ğŸ“Œ í‚¤ì›Œë“œ:** {', '.join(keywords)}\n\n")
            readme.write("## ğŸ“„ í¬í•¨ëœ íŒŒì¼ ëª©ë¡\n")
            for f in filenames:
                original_name = f.split("_", 1)[-1] if "_" in f else f
                readme.write(f"- {original_name}\n")
            saved_files.append(readme_path)

        for f in filenames:
            match = file_id_map.get(f)
            if match:
                output_path = os.path.join(folder, match["filename"])
                with open(output_path, "w", encoding="utf-8") as md_file:
                    md_file.write(match["content"])
                saved_files.append(output_path)

    if saved_files:
        zip_path = os.path.join(temp_dir, "merged_markdowns.zip")
        with zipfile.ZipFile(zip_path, "w") as zipf:
            for filepath in saved_files:
                arcname = os.path.relpath(filepath, temp_dir)
                zipf.write(filepath, arcname)

        with open(zip_path, "rb") as fp:
            st.download_button("ğŸ“¦ ë³‘í•© ZIP ë‹¤ìš´ë¡œë“œ", fp, file_name="merged_markdowns.zip", mime="application/zip")

        shutil.rmtree(temp_dir)
        st.caption("â€» ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì´í›„ ì„ì‹œ í´ë”ëŠ” ìë™ ì‚­ì œë©ë‹ˆë‹¤.")
    else:
        st.error("âš ï¸ ë³‘í•©ëœ íŒŒì¼ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
