import streamlit as st
from openai import OpenAI
import os
import tempfile
import shutil
import zipfile
from concurrent.futures import ThreadPoolExecutor, as_completed

# âœ… OpenAI SDK v1+
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ğŸ“ Markdown ìë™ ë¶„ë¥˜ê¸°", page_icon="ğŸ“š", layout="wide")
st.title("ğŸ“ ChatGPT ê¸°ë°˜ Markdown ìë™ ë¶„ë¥˜ + ë³‘í•© ë„êµ¬")

st.markdown("""
Markdown íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ GPTê°€ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ì£¼ì œë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ZIP íŒŒì¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.
""")

# âœ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "zip_path" not in st.session_state:
    st.session_state.zip_path = None
    st.session_state.grouped = None
    st.session_state.file_infos = None
    st.session_state.analysis_done = False
    st.session_state.show_confirm = False  # ì´ˆê¸°í™” í™•ì¥ì°½ í‘œì‹œ ì—¬ë¶€

# âœ… ì‚¬ì´ë“œë°”: ëª¨ë¸ ì„ íƒ + ì´ˆê¸°í™” ë²„íŠ¼
st.sidebar.markdown("## âš™ï¸ ì„¤ì •")

model_choice = st.sidebar.selectbox(
    "ğŸ“Œ ì‚¬ìš©í•  GPT ëª¨ë¸",
    ["gpt-5-nano", "gpt-3.5-turbo"],
    index=0,
)

# ğŸ”„ ì´ˆê¸°í™” ìš”ì²­ â†’ í™•ì¥ í™•ì¸ì°½ ë„ìš°ê¸°
if st.sidebar.button("ğŸ”„ ë‹¤ì‹œ ì‹œì‘"):
    st.session_state.show_confirm = True

# âœ… ì´ˆê¸°í™” í™•ì¸ì°½
if st.session_state.show_confirm:
    with st.sidebar.expander("âš ï¸ ì •ë§ ì´ˆê¸°í™”í• ê¹Œìš”?", expanded=True):
        st.warning("ëª¨ë“  ë¶„ì„ ê²°ê³¼ì™€ ì—…ë¡œë“œëœ íŒŒì¼ì´ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ì˜ˆ, ì´ˆê¸°í™”í• ê²Œìš”"):
                st.session_state.clear()
                st.experimental_rerun()
        with col2:
            if st.button("âŒ ì·¨ì†Œ"):
                st.session_state.show_confirm = False

# âœ… ê³ ì • ìƒíƒœ ë©”ì‹œì§€ í•¨ìˆ˜
def show_fixed_status(msg):
    st.markdown(
        f"""
        <div style="
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            background-color: #fef3c7;
            color: #000;
            padding: 12px 20px;
            z-index: 1000;
            font-weight: bold;
            border-bottom: 1px solid #e0e0e0;
            text-align: center;
        ">
        {msg}
        </div>
        <br><br><br>
        """,
        unsafe_allow_html=True
    )

# âœ… GPT íƒœê·¸ ì¶”ì¶œ í•¨ìˆ˜
def extract_tags(filename, content):
    prompt = f"{T['prompt']}\n\në¬¸ì„œëª…: {filename}\në‚´ìš©:\n{content[:1000].rsplit('\\n', 1)[0]}..."
    try:
        res = client.chat.completions.create(
            model=model_choice,
            messages=[{"role": "user", "content": prompt}]
        )
        text = res.choices[0].message.content.strip()
        tags = []
        for line in text.split("\n"):
            if "íƒœê·¸:" in line or "Tags:" in line:
                tag_str = line.split(":", 1)[1]
                tags = [t.strip().lower() for t in tag_str.split(",") if t.strip()]
        return tags
    except Exception:
        return []

# âœ… íƒœê·¸ ê¸°ë°˜ ê·¸ë£¹í•‘
def group_by_tags(file_infos):
    tag_to_files = defaultdict(list)
    for info in file_infos:
        for tag in info["tags"]:
            tag_to_files[tag].append(info)

    grouped = {}
    used = set()
    group_num = 1
    for tag, files in tag_to_files.items():
        group_files = [f for f in files if f["filename"] not in used]
        if not group_files:
            continue
        group_name = f"Group {group_num}: {tag}"
        grouped[group_name] = {
            "files": [f["filename"] for f in group_files],
            "keywords": list(set(tag for f in group_files for tag in f["tags"]))
        }
        for f in group_files:
            used.add(f["filename"])
        group_num += 1

    return grouped

# âœ… ì¢Œìš° ì»¬ëŸ¼ UI
left, right = st.columns([1.2, 2.8])
with left:
    uploaded_files = st.file_uploader(T["upload_label"], type="md", accept_multiple_files=True)

with right:
    st.markdown(f"### {T['download_box']}")
    if st.session_state.analysis_done and st.session_state.zip_path:
        with open(st.session_state.zip_path, "rb") as fp:
            st.download_button(T["download_btn"], fp, file_name="tag_grouped_markdowns.zip", mime="application/zip")
        st.success(T["download_info"])
    else:
        st.info(T["waiting_info"])

# âœ… ë¶„ì„ ë° ê·¸ë£¹í•‘
if uploaded_files and not st.session_state.analysis_done:
    show_fixed_status(T["progress_title"])
    start_time = time.time()

    file_infos = []
    seen = set()
    future_to_file = {}

    progress = st.empty()
    status_text = st.empty()
    log_area = st.container()

    with ThreadPoolExecutor(max_workers=10) as executor:
        for file in uploaded_files:
            name = file.name
            if name in seen:
                continue
            seen.add(name)
            content = file.read().decode("utf-8")
            future = executor.submit(extract_tags, name, content)
            future_to_file[future] = {"filename": name, "content": content}

        for i, future in enumerate(as_completed(future_to_file)):
            tags = future.result()
            info = future_to_file[future]
            info["tags"] = tags
            file_infos.append(info)

            percent = (i + 1) / len(future_to_file)
            progress.progress(percent)
            status_text.markdown(f"ğŸ“„ `{info['filename']}` {T['analyzing']} ({int(percent*100)}%)")
            log_area.markdown(f"âœ… `{info['filename']}` â†’ {T['tags']}: {', '.join(tags)}")

    grouped = group_by_tags(file_infos)
    
    # âœ… ZIP ìƒì„±
    temp_dir = tempfile.mkdtemp()
    saved_files = []

    for topic, group_data in grouped.items():
        filenames = group_data["files"]
        keywords = group_data.get("keywords", [])
        folder = os.path.join(temp_dir, topic.replace(" ", "_"))
        os.makedirs(folder, exist_ok=True)

        readme_path = os.path.join(folder, "README.md")
        with open(readme_path, "w", encoding="utf-8") as readme:
            readme.write(f"# {topic}\n\n")
            if keywords:
                readme.write(f"**ğŸ“Œ í‚¤ì›Œë“œ:** {', '.join(keywords)}\n\n")
            readme.write("## ğŸ“„ í¬í•¨ëœ íŒŒì¼ ëª©ë¡\n")
            for f in filenames:
                readme.write(f"- {f}\n")
            saved_files.append(readme_path)

        for f in filenames:
            match = next((item for item in file_infos if item["filename"] == f), None)
            if match:
                full_path = os.path.join(folder, f)
                with open(full_path, "w", encoding="utf-8") as md_file:
                    md_file.write(match["content"])
                saved_files.append(full_path)

    zip_path = os.path.join(temp_dir, "merged_markdowns.zip")
    with zipfile.ZipFile(zip_path, "w") as zipf:
        for filepath in saved_files:
            arcname = os.path.relpath(filepath, temp_dir)
            zipf.write(filepath, arcname)

    # âœ… ì„¸ì…˜ ìƒíƒœ ì €ì¥
    st.session_state.zip_path = zip_path
    st.session_state.grouped = grouped
    st.session_state.file_infos = file_infos
    st.session_state.analysis_done = True
