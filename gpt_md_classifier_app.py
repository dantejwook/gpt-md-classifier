import streamlit as st
from openai import OpenAI
import os
import tempfile
import shutil
import zipfile
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import json
import openai
import backoff

# OpenAI Client ìƒì„±
client = OpenAI(api_key=st.secrets.get("OPENAI_API_KEY"))

st.set_page_config(
    page_title="ğŸ“ Markdown ìë™ ë³‘í•© ë¶„ë¥˜ê¸°",
    page_icon="ğŸ“š",
    layout="wide"
)

st.title("ğŸ“ ChatGPT ê¸°ë°˜ Markdown ìë™ ë¶„ë¥˜ + ì£¼ì œ ë³‘í•©")
st.markdown("""
ì—…ë¡œë“œí•œ Markdown íŒŒì¼ë“¤ì„ GPTê°€ ìë™ ë¶„ì„í•˜ì—¬ **ì‹œë„ˆì§€ ìˆëŠ” ì£¼ì œ ê·¸ë£¹**ìœ¼ë¡œ ë¬¶ì–´ì¤ë‹ˆë‹¤.  
íŒŒì¼ì€ 10ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬ë˜ë©°, ëª¨ë“  ê²°ê³¼ëŠ” ZIPìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

uploaded_files = st.file_uploader(
    "â¬†ï¸ Markdown (.md) íŒŒì¼ ì—…ë¡œë“œ (ìµœëŒ€ 100ê°œ)",
    type="md",
    accept_multiple_files=True
)

if not client.api_key:
    st.error("â— OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

# ------------------------------
# Retry ì²˜ë¦¬ - GPT ìš”ì²­ ì¬ì‹œë„
# ------------------------------
@backoff.on_exception(backoff.expo, openai.RateLimitError, max_tries=3)
def get_topic_and_summary(filename, content):
    prompt = f"""
ë‹¤ìŒì€ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œì…ë‹ˆë‹¤. ì•„ë˜ ë¬¸ì„œì˜ ì£¼ìš” ì£¼ì œë¥¼ ì§§ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ, í•µì‹¬ ìš”ì•½ë„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ì¶œë ¥ í˜•ì‹:
ì£¼ì œ: [ì£¼ì œëª…]
ìš”ì•½: [ìš”ì•½ë‚´ìš©]

ë¬¸ì„œ ì œëª©: {filename}
ë‚´ìš©:
{content[:1000]}
"""
    try:
        res = client.chat.completions.create(
            model="gpt-3.5-turbo",  # í˜¹ì€ gpt-4-turbo ì‚¬ìš© ê°€ëŠ¥
            messages=[{"role": "user", "content": prompt}]
        )
        text = res.choices[0].message.content.strip()
        topic = "Unknown"
        summary = ""
        for line in text.split("\n"):
            if line.lower().startswith("ì£¼ì œ:"):
                topic = line.split(":", 1)[1].strip()
            elif line.lower().startswith("ìš”ì•½:"):
                summary = line.split(":", 1)[1].strip()
        return topic or "Unknown", summary
    except Exception as e:
        st.warning(f"âš ï¸ {filename} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "Unknown", ""


def get_grouped_topics(file_infos):
    merge_prompt = """
ë‹¤ìŒì€ ì—¬ëŸ¬ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ì£¼ì œ ë° ìš”ì•½ì…ë‹ˆë‹¤. ì£¼ì œì™€ ìš”ì•½ì´ ìœ ì‚¬í•˜ê±°ë‚˜ ê´€ë ¨ ìˆëŠ” íŒŒì¼ë¼ë¦¬ ë¬¶ì–´ 5~10ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ ì£¼ì„¸ìš”.
ê·¸ë¦¬ê³  ê° ê·¸ë£¹ì— ì ì ˆí•œ ëŒ€í‘œ í‚¤ì›Œë“œë¥¼ 3~5ê°œ ìƒì„±í•´ì£¼ì„¸ìš”.
ì¶œë ¥ í˜•ì‹:
[ê·¸ë£¹ëª…]: íŒŒì¼1.md, íŒŒì¼2.md
í‚¤ì›Œë“œ: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3

ëª©ë¡:
"""
    for info in file_infos:
        merge_prompt += f"- {info['filename']}: {info['topic']} / {info['summary']}\n"

    try:
        res = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": merge_prompt}]
        )
        text = res.choices[0].message.content.strip()
        groups = {}
        current_group = None
        for line in text.split("\n"):
            if ":" in line and ".md" in line:
                topic, files_str = line.split(":", 1)
                filenames = [f.strip() for f in files_str.split(",") if f.strip()]
                current_group = topic.strip()
                groups[current_group] = {"files": filenames, "keywords": []}
            elif "í‚¤ì›Œë“œ:" in line and current_group:
                keyword_str = line.split(":", 1)[1]
                groups[current_group]["keywords"] = [k.strip() for k in keyword_str.split(",")]
        return g
