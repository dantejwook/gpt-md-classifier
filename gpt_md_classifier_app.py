import streamlit as st
from openai import OpenAI
import os
import tempfile
import shutil
import zipfile
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict, Counter
import time

# ğŸŒ ë‹¤êµ­ì–´ ì„¤ì •
LANG = st.sidebar.selectbox("ğŸŒ Language", ["í•œêµ­ì–´", "English"])
is_ko = LANG == "í•œêµ­ì–´"

# í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬
T = {
    "title": "ğŸ§© GPT ê¸°ë°˜ Markdown íƒœê·¸ ë¶„ë¥˜ê¸°" if is_ko else "ğŸ§© GPT-based Markdown Tag Grouper",
    "desc": "Markdown íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ GPTê°€ íƒœê·¸ë¥¼ ì¶”ì¶œí•˜ê³  ê·¸ë£¹í™”í•˜ì—¬ ZIP íŒŒì¼ë¡œ ì œê³µí•©ë‹ˆë‹¤." if is_ko else "Upload markdown files, and GPT will extract tags and group them into a ZIP.",
    "upload": "â¬†ï¸ Markdown (.md) íŒŒì¼ ì—…ë¡œë“œ" if is_ko else "â¬†ï¸ Upload Markdown Files",
    "model": "ğŸ“Œ ì‚¬ìš©í•  GPT ëª¨ë¸" if is_ko else "ğŸ“Œ GPT Model",
    "restart": "ğŸ”„ ë‹¤ì‹œ ì‹œì‘" if is_ko else "ğŸ”„ Restart",
    "confirm_restart": "ì •ë§ ë‹¤ì‹œ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?" if is_ko else "Are you sure you want to restart?",
    "yes": "ì˜ˆ" if is_ko else "Yes",
    "no": "ì•„ë‹ˆì˜¤" if is_ko else "No",
    "progress_title": "ğŸ“Š íƒœê·¸ ì¶”ì¶œ ë° ê·¸ë£¹í™” ì§„í–‰ ì¤‘..." if is_ko else "ğŸ“Š Extracting tags and grouping...",
    "progress_done": "âœ… ë¶„ì„ ì™„ë£Œ" if is_ko else "âœ… Analysis complete",
    "download_btn": "ğŸ“¥ ZIP ë‹¤ìš´ë¡œë“œ" if is_ko else "ğŸ“¥ Download ZIP",
    "caption": "â€» ë‹¤ìš´ë¡œë“œ í›„ ì„ì‹œ í´ë”ëŠ” ìë™ ì‚­ì œë©ë‹ˆë‹¤." if is_ko else "â€» Temp folder is deleted after download.",
    "group": "ê·¸ë£¹" if is_ko else "Group",
    "tag": "íƒœê·¸" if is_ko else "Tags",
    "file_count": "ğŸ“„ íŒŒì¼ ìˆ˜" if is_ko else "ğŸ“„ File count"
}

# âœ… OpenAI Client
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… Streamlit ì„¤ì •
st.set_page_config(page_title="ğŸ“ Markdown ìë™ ë¶„ë¥˜ê¸°", page_icon="ğŸ“š", layout="wide")
st.title(T["title"])
st.markdown(T["desc"])

# âœ… ì‚¬ì´ë“œë°” ì„¤ì •
model_choice = st.sidebar.selectbox(T["model"], ["gpt-5-nano"], index=0)

# ğŸ” ë‹¤ì‹œ ì‹œì‘ ë²„íŠ¼
if st.sidebar.button(T["restart"]):
    if st.sidebar.radio(T["confirm_restart"], [T["yes"], T["no"]]) == T["yes"]:
        st.session_state.clear()
        st.experimental_rerun()

# âœ… ì—…ë¡œë“œ UI
left_col, right_col = st.columns([1.5, 2.5])
with left_col:
    uploaded_files = st.file_uploader(T["upload"], type="md", accept_multiple_files=True)

with right_col:
    if "zip_path" in st.session_state and st.session_state["zip_path"]:
        with open(st.session_state["zip_path"], "rb") as fp:
            st.download_button(T["download_btn"], fp, file_name="tag_grouped_markdowns.zip", mime="application/zip")
        st.success(T["progress_done"])
        st.caption(T["caption"])

# âœ… ìƒíƒœ ë©”ì‹œì§€ ìƒë‹¨ ê³ ì •
def show_fixed_status(msg):
    st.markdown(f"""
    <div style="
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        background-color: #fceabb;
        color: black;
        padding: 10px;
        z-index: 1000;
        text-align: center;
        font-weight: bold;
        border-bottom: 1px solid #e0e0e0;
    ">
        {msg}
    </div>
    <br><br><br>
    """, unsafe_allow_html=True)

# âœ… GPT: í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
def extract_tags(filename, content):
    prompt = f"""
ë‹¤ìŒì€ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œì…ë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ë˜ëŠ” ì£¼ì œ 3~5ê°œë¥¼ ë½‘ì•„ì£¼ì„¸ìš”. í•œê¸€ ë˜ëŠ” ì˜ì–´ ë‹¨ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”.
ì¶œë ¥ í˜•ì‹:
íƒœê·¸: tag1, tag2, tag3

ë¬¸ì„œëª…: {filename}
ë‚´ìš©:
{content[:1000].rsplit('\\n', 1)[0]}...
""" if is_ko else f"""
This is a markdown file. Please extract 3 to 5 major keywords or tags that represent its topic. Output in a simple list format.
Output format:
Tags: tag1, tag2, tag3

Filename: {filename}
Content:
{content[:1000].rsplit('\\n', 1)[0]}...
"""
    try:
        res = client.chat.completions.create(
            model=model_choice,
            messages=[{"role": "user", "content": prompt}]
        )
        text = res.choices[0].message.content.strip()
        tags = []
        for line in text.split("\n"):
            if "íƒœê·¸:" in line or "Tags:" in line:
                tag_str = line.split(":", 1)[1]
                tags = [t.strip().lower() for t in tag_str.split(",") if t.strip()]
        return tags
    except Exception as e:
        return []

# âœ… íƒœê·¸ ê¸°ë°˜ ê·¸ë£¹í•‘ í•¨ìˆ˜
def group_by_tags(file_infos):
    tag_to_files = defaultdict(list)
    for info in file_infos:
        for tag in info["tags"]:
            tag_to_files[tag].append(info)

    grouped = {}
    used_files = set()
    group_num = 1

    for tag, files in tag_to_files.items():
        group_files = [f for f in files if f["filename"] not in used_files]
        if not group_files:
            continue
        group_name = f"{T['group']} {group_num}: {tag}"
        grouped[group_name] = {
            "files": [f["filename"] for f in group_files],
            "keywords": list(set(t for f in group_files for t in f["tags"]))
        }
        for f in group_files:
            used_files.add(f["filename"])
        group_num += 1
    return grouped

# âœ… ì¢Œìš° ì»¬ëŸ¼ UI
left, right = st.columns([1.2, 2.8])
with left:
    uploaded_files = st.file_uploader(T["upload_label"], type="md", accept_multiple_files=True)

with right:
    st.markdown(f"### {T['download_box']}")
    if st.session_state.analysis_done and st.session_state.zip_path:
        with open(st.session_state.zip_path, "rb") as fp:
            st.download_button(T["download_btn"], fp, file_name="tag_grouped_markdowns.zip", mime="application/zip")
        st.success(T["download_info"])
    else:
        st.info(T["waiting_info"])

# âœ… ë©”ì¸ ì‹¤í–‰
if uploaded_files and "zip_path" not in st.session_state:
    start_time = time.time()
    show_fixed_status(T["progress_title"])

    file_infos = []
    seen = set()
    future_to_file = {}
    progress = st.progress(0.0)
    status = st.empty()
    log_area = st.container()

    with ThreadPoolExecutor(max_workers=10) as executor:
        for file in uploaded_files:
            name = file.name
            if name in seen:
                continue
            seen.add(name)
            content = file.read().decode("utf-8")
            future = executor.submit(extract_tags, name, content)
            future_to_file[future] = {"filename": name, "content": content}

        for i, future in enumerate(as_completed(future_to_file)):
            tags = future.result()
            info = future_to_file[future]
            info["tags"] = tags
            file_infos.append(info)

            percent = (i + 1) / len(future_to_file)
            progress.progress(percent)
            status.markdown(f"ğŸ“„ `{info['filename']}` â†’ {T['tag']}: {', '.join(tags)}")

    grouped = group_by_tags(file_infos)

    # âœ… ê·¸ë£¹ ê²°ê³¼ ì €ì¥
    temp_dir = tempfile.mkdtemp()
    saved_files = []

    for topic, group_data in grouped.items():
        folder = os.path.join(temp_dir, topic.replace(" ", "_"))
        os.makedirs(folder, exist_ok=True)

        readme_path = os.path.join(folder, "README.md")
        with open(readme_path, "w", encoding="utf-8") as readme:
            readme.write(f"# {topic}\n\n")
            readme.write(f"**ğŸ“Œ {T['tag']}:** {', '.join(group_data['keywords'])}\n\n")
            readme.write(f"## ğŸ“„ {T['file_count']}\n")
            for fname in group_data["files"]:
                readme.write(f"- {fname}\n")
            saved_files.append(readme_path)

        for fname in group_data["files"]:
            match = next((f for f in file_infos if f["filename"] == fname), None)
            if match:
                path = os.path.join(folder, fname)
                with open(path, "w", encoding="utf-8") as f:
                    f.write(match["content"])
                saved_files.append(path)

    # âœ… í‚¤ì›Œë“œ  ë¹ˆë„ ìš”ì•½
    all_tags = [tag for f in file_infos for tag in f["tags"]]
    tag_counts = Counter(all_tags)
    summary_path = os.path.join(temp_dir, "tags_summary.md")
    with open(summary_path, "w", encoding="utf-8") as f:
        f.write("# ğŸ“Š í‚¤ì›Œë“œ ì‚¬ìš© ë¹ˆë„ ìš”ì•½\n\n" if is_ko else "# ğŸ“Š Tag Usage Summary\n\n")
        f.write("| í‚¤ì›Œë“œ | ì‚¬ìš© íšŸìˆ˜ |\n|------|----------|\n" if is_ko else "| Tag | Count |\n|------|----------|\n")
        for tag, count in tag_counts.most_common():
            f.write(f"| `{tag}` | {count} |\n")
    saved_files.append(summary_path)

    # âœ… ZIP ì••ì¶•
    zip_path = os.path.join(temp_dir, "tag_grouped_markdowns.zip")
    with zipfile.ZipFile(zip_path, "w") as zipf:
        for path in saved_files:
            arcname = os.path.relpath(path, temp_dir)
            zipf.write(path, arcname)

    elapsed = time.time() - start_time
    minutes, seconds = divmod(elapsed, 60)
    show_fixed_status(T["progress_done"])
    st.success(f"â± ë¶„ì„ ì†Œìš” ì‹œê°„: {int(minutes)}ë¶„ {int(seconds)}ì´ˆ" if is_ko else f"â± Elapsed time: {int(minutes)} min {int(seconds)} sec")

    # âœ… ì„¸ì…˜ ì €ì¥
    st.experimental_rerun()
