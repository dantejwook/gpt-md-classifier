import streamlit as st
import os
import pdfplumber
import markdown2
import openai
import tempfile
from sklearn.cluster import KMeans
import numpy as np
from typing import List
from io import StringIO

# Set your OpenAI key
openai.api_key = st.secrets["OPENAI_API_KEY"] if "OPENAI_API_KEY" in st.secrets else os.getenv("OPENAI_API_KEY")

# ----- 1. ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ -----
def extract_text(file) -> str:
    name = file.name.lower()
    if name.endswith(".pdf"):
        with pdfplumber.open(file) as pdf:
            return "\n".join([page.extract_text() or "" for page in pdf.pages])
    elif name.endswith(".md"):
        return markdown2.markdown(file.read().decode("utf-8"))
    elif name.endswith(".txt"):
        return file.read().decode("utf-8")
    else:
        return ""

# ----- 2. ì„ë² ë”© ìƒì„± -----
def get_embedding(text: str) -> List[float]:
    response = openai.embeddings.create(
        model="text-embedding-3-small",
        input=text[:8000]  # truncate if too long
    )
    return response.data[0].embedding

# ----- 3. í´ëŸ¬ìŠ¤í„°ë§ -----
def cluster_embeddings(embeddings: List[List[float]], n_clusters: int):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(embeddings)
    return labels

# ----- 4. í´ëŸ¬ìŠ¤í„° ìš”ì•½ (GPT ì‚¬ìš© optional) -----
def summarize_cluster(docs: List[str]):
    joined = "\n\n".join(docs)
    prompt = f"ë‹¤ìŒ ë¬¸ì„œë“¤ì˜ ê³µí†µ ì£¼ì œë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”:\n\n{joined[:4000]}"
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content.strip()

# ----- 5. Streamlit UI -----
st.title("ğŸ“„ Embedding ê¸°ë°˜ ë¬¸ì„œ ë¶„ë¥˜ê¸°")
st.markdown("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ì„ë² ë”©ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œë¼ë¦¬ ìë™ ë¶„ë¥˜í•©ë‹ˆë‹¤.")

uploaded_files = st.file_uploader("ë¬¸ì„œ íŒŒì¼ ì—…ë¡œë“œ (.txt, .md, .pdf)", type=["txt", "md", "pdf"], accept_multiple_files=True)

if uploaded_files:
    with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘..."):
        docs_text = []
        file_names = []
        for file in uploaded_files:
            text = extract_text(file)
            if text:
                docs_text.append(text)
                file_names.append(file.name)

        embeddings = [get_embedding(text) for text in docs_text]

        n_clusters = st.slider("ë¶„ë¥˜ ê°œìˆ˜(KMeans í´ëŸ¬ìŠ¤í„° ìˆ˜)", 2, min(10, len(embeddings)), 3)

        labels = cluster_embeddings(embeddings, n_clusters)

        # í´ëŸ¬ìŠ¤í„°ë³„ ë¬¸ì„œ ì •ë¦¬
        clustered_docs = {}
        for label, name, text in zip(labels, file_names, docs_text):
            clustered_docs.setdefault(label, []).append((name, text))

    st.success("ë¶„ë¥˜ ì™„ë£Œ! ğŸ“")

    for cluster_id, docs in clustered_docs.items():
        with st.expander(f"ğŸ“‚ í´ëŸ¬ìŠ¤í„° {cluster_id} â€” ë¬¸ì„œ {len(docs)}ê°œ"):
            st.markdown("**í¬í•¨ ë¬¸ì„œ:**")
            for name, _ in docs:
                st.markdown(f"- {name}")

            if st.checkbox(f"í´ëŸ¬ìŠ¤í„° {cluster_id} ìš”ì•½ ë³´ê¸°", key=f"sum_{cluster_id}"):
                with st.spinner("GPTë¡œ í´ëŸ¬ìŠ¤í„° ì£¼ì œ ë¶„ì„ ì¤‘..."):
                    cluster_texts = [text for _, text in docs]
                    summary = summarize_cluster(cluster_texts)
                    st.markdown(f"**ê³µí†µ ì£¼ì œ ìš”ì•½:** {summary}")
