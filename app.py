import streamlit as st
import os
import pdfplumber
import openai
import tempfile
import zipfile
from sklearn.cluster import KMeans
from typing import List, Dict, Tuple

# ===============================
# OpenAI API Key
# ===============================
try:
    openai.api_key = (
        st.secrets["OPENAI_API_KEY"]
        if "OPENAI_API_KEY" in st.secrets
        else os.getenv("OPENAI_API_KEY")
    )
    if not openai.api_key:
        st.stop()
        st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ í™•ì¸!")
except Exception as e:
    st.stop()
    st.error(f"âŒ API í‚¤ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ===============================
# í…ìŠ¤íŠ¸ ì¶”ì¶œ
# ===============================
def extract_text_for_embedding(file) -> str:
    name = file.name.lower()
    try:
        if name.endswith(".pdf"):
            with pdfplumber.open(file) as pdf:
                return "\n".join([page.extract_text() or "" for page in pdf.pages])
        elif name.endswith(".md"):
            return file.read().decode("utf-8")
        elif name.endswith(".txt"):
            return file.read().decode("utf-8")
        else:
            return ""
    except Exception as e:
        st.warning(f"âš ï¸ íŒŒì¼ {file.name} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

# ===============================
# ì„ë² ë”© ìƒì„± (ì˜¤ë¥˜ ì¡í˜)
# ===============================
def get_embedding(text: str) -> List[float]:
    if not text.strip():
        raise ValueError("âš ï¸ ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ì„ë² ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    try:
        response = openai.embeddings.create(
            model="text-embedding-3-small",
            input=text[:8000]
        )
        return response.data[0].embedding
    except Exception as e:
        raise RuntimeError(f"âŒ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

# ===============================
# í´ëŸ¬ìŠ¤í„°ë§
# ===============================
def cluster_embeddings(embeddings: List[List[float]], n_clusters: int):
    try:
        model = KMeans(n_clusters=n_clusters, random_state=42)
        return model.fit_predict(embeddings)
    except Exception as e:
        raise RuntimeError(f"âŒ í´ëŸ¬ìŠ¤í„°ë§ ì¤‘ ì˜¤ë¥˜: {e}")

# ===============================
# GPT ìš”ì•½
# ===============================
def summarize_cluster_md(texts: List[str], filenames: List[str]) -> str:
    try:
        joined = "\n\n".join(texts)[:4000]
        file_list = "\n".join(f"- {f}" for f in filenames)

        prompt = f"""
ì•„ë˜ ë¬¸ì„œ ë¬¶ìŒì„ ë¶„ì„í•´ì„œ Markdown í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

í¬í•¨ ë¬¸ì„œ:
{file_list}

ìš”êµ¬ í˜•ì‹:

## ğŸ“Œ ê³µí†µ ì£¼ì œ
- í•œ ë¬¸ì¥

## ğŸ“ ìš”ì•½
- 3~5ì¤„ ìš”ì•½

## ğŸ· ì£¼ìš” í‚¤ì›Œë“œ
- í‚¤ì›Œë“œ ë‚˜ì—´ (bullet)

ë¬¸ì„œ ë‚´ìš©:
{joined}
"""

        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"âŒ GPT ìš”ì•½ ì‹¤íŒ¨: {e}"

# ===============================
# ZIP ìƒì„±
# ===============================
def create_cluster_zip(
    clustered_docs: Dict[int, List[Tuple[str, bytes, str]]]
) -> bytes:
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            zip_path = os.path.join(temp_dir, "clustered_documents.zip")

            for cluster_id, docs in clustered_docs.items():
                cluster_dir = os.path.join(temp_dir, f"cluster_{cluster_id}")
                os.makedirs(cluster_dir, exist_ok=True)

                texts_for_summary = []
                filenames = []

                for filename, raw_bytes, extracted_text in docs:
                    filenames.append(filename)
                    texts_for_summary.append(extracted_text)

                    file_path = os.path.join(cluster_dir, filename)
                    with open(file_path, "wb") as f:
                        f.write(raw_bytes)

                summary_md = summarize_cluster_md(texts_for_summary, filenames)
                with open(os.path.join(cluster_dir, "README.md"), "w", encoding="utf-8") as f:
                    f.write(summary_md)

            with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zipf:
                for root, _, files in os.walk(temp_dir):
                    for file in files:
                        if file.endswith(".zip"):
                            continue
                        full_path = os.path.join(root, file)
                        arcname = os.path.relpath(full_path, temp_dir)
                        zipf.write(full_path, arcname)

            with open(zip_path, "rb") as f:
                return f.read()

    except Exception as e:
        st.error(f"âŒ ZIP ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return b""

# ===============================
# Streamlit UI
# ===============================
st.set_page_config("ë””ë²„ê·¸ ë¬¸ì„œ ë¶„ë¥˜ê¸°", layout="wide")
st.title("ğŸ Embedding ê¸°ë°˜ ë¬¸ì„œ ë¶„ë¥˜ê¸° (ë””ë²„ê¹… ëª¨ë“œ)")

uploaded_files = st.file_uploader(
    "ë¬¸ì„œ ì—…ë¡œë“œ (.pdf, .md, .txt)",
    type=["pdf", "md", "txt"],
    accept_multiple_files=True
)

if uploaded_files:
    try:
        extracted_texts = []
        embeddings = []
        raw_files = []

        with st.spinner("ì„ë² ë”© ì²˜ë¦¬ ì¤‘..."):
            for file in uploaded_files:
                raw_bytes = file.read()
                text = extract_text_for_embedding(file)

                if not text.strip():
                    st.warning(f"âš ï¸ {file.name} ëŠ” ë¹ˆ ë¬¸ì„œì…ë‹ˆë‹¤.")
                    continue

                embedding = get_embedding(text)

                extracted_texts.append(text)
                embeddings.append(embedding)
                raw_files.append((file.name, raw_bytes, text))

        if len(embeddings) < 2:
            st.warning("âš ï¸ í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•´ ìµœì†Œ 2ê°œ ë¬¸ì„œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()

        n_clusters = st.slider(
            "í´ëŸ¬ìŠ¤í„° ê°œìˆ˜",
            2,
            min(10, len(embeddings)),
            3
        )

        labels = cluster_embeddings(embeddings, n_clusters)

        clustered_docs = {}
        for label, file_data in zip(labels, raw_files):
            clustered_docs.setdefault(label, []).append(file_data)

        st.success("âœ… ë¬¸ì„œ ë¶„ë¥˜ ì™„ë£Œ")

        for cid, docs in clustered_docs.items():
            with st.expander(f"ğŸ“ Cluster {cid}"):
                for name, _, _ in docs:
                    st.markdown(f"- {name}")

        zip_bytes = create_cluster_zip(clustered_docs)

        st.download_button(
            "ğŸ“¦ í´ëŸ¬ìŠ¤í„° ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ",
            data=zip_bytes,
            file_name="clustered_documents.zip",
            mime="application/zip"
        )

    except Exception as e:
        st.error(f"âŒ ì²˜ë¦¬ ë„ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
